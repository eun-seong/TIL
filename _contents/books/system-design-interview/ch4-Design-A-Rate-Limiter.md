---
title: Chap4. 처리율 제한 장치의 설계
docType: book
---

처리율 제한 장치(rate limiter) : 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치

예를 들어
* 사용자는 초당 2회 이상 새 글을 올릴 수 없다
* 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다
* 같은 디바이스로는 주당 5회 이상 리워드(reward)를 요청할 수 없다


### 처리율 제한 장치를 두면 좋은 점
* DoS 공격에 의한 자원 고갈을 방지할 수 있음
* 비용 절감
* 서버 과부하 방지


# 처리율 제한 장치
throttle 개념과 유사하다.

처리율 제한 알고리즘의 기본 아이디어는
* 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 추적 대상별로 두고
* 이 카운터의 값이 어떤 한도를 넘어서면 그 이후 도착한 요청은 거부하는 것
으로 단순하다.

## 요약
1. 작업 프로세스는 수시로 처리율 제한 규칙을 디스크에서 읽어서 캐시에 저장한다.
2. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다.
3. 아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다.
    * 요청이 처리율 제한에 걸리지 않은 경우 API 서버로 보낸다
    * 요청이 걸릴 경우, 429 too many requests 에러를 뱉는다. 해당 요청은 버릴 수도 있고, 큐에 보관할 수도 있다.



## 처리율 제한 장치는 어디에 두면 좋을까
* 클라이언트
  둘 수는 있다. 하지만 쉽게 위변조가 가능해서, 모든 클라이언트의 구현을 통제하는 것은 어려울 수도 있다.

* 서버
  * API 서버 측에 두기
  * 처리율 제한 미들웨어 만들기 -> API 서버로 가는 요청을 통제
    클라우드 서비스에서는 보통 API gateway에서 처리한다.


## 처리율 제한 알고리즘

### token bucket
지정된 용량을 갖는 컨테이너

* 주기적으로 버킷에 토큰이 채워진다.
* 토큰이 꽉 찬 버킷에는 더 이상의 토큰이 추가되지 않는다.
* 각 요청은 처리될 때마다 하나의 토큰을 사용한다.
* 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다.
  * 충분한 토큰이 있을 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
  * 충분한 토큰이 없는 경우, 해당 요청은 버려진다.


공급 제한 규칙에 따라 버킷의 개수는 달라진다.
* 사용자마다
* IP 주소마다
* 시스템 처리율을 제한한다면, 모든 요청이 하나의 버킷을 공유

#### 장점
* 구현이 쉬움
* 효율적인 메모리 사용
* 짧은 시간에 집중되는 트래픽 처리 가능

#### 단점
* 적절한 버킷 크기와 토큰 공급률 값을 튜닝하기 까다롭다



### leaky bucket
token bucket과 유사, 요청 처리율이 고정되어 있음.

* 보통 **큐**로 구현한다.
* 고정 속도로 요청을 처리한다.(지정된 시간마다 큐에서 요청 꺼냄)
* 요청이 도착하면 큐가 가득 차 있는지 확인
  * 빈자리가 있을 경우, 큐에 요청을 추가
  * 가득 차 있을 경우, 새 요청은 버림

#### 장점
* 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
* 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합

#### 단점
* 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청이 쌓이고, 이 요청들을 제때 처리하지 못하면 최신 요청들이 버려지게 된다.
* 적절한 버킷 크기, 처리율 값을 튜닝하기 까다롭다.




### fixed window counter
* 타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 붙인다.
* 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
* 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려진다.

#### 장점
* 메모리 효율이 좋다.
* 이해하기 쉽다.
* 특정한 트래픽 패턴을 처리하기에 적합하다.

#### 단점
* 윈도우 경계 부근에 순간적으로 많은 트래픽이 집중될 수 있다. -> 기존 할당된 양보다 더 많은 요청이 처리될 수 있다.
  ex) 윈도우가 1분이고 임계치(threshold)가 10개일 때, 00:55~01:05 사이에 20개의 트래픽을 처리하게 될 수 있다. 허용 한도의 2배이다.



### sliding window log
고정 윈도우 카운터 알고리즘의 단점을 보완할 수 있는 알고리즘이다.

* 타임스탬프를 추적한다. - 타임스탬프는 보통 redis의 sorted set과 같은 캐시에 보관한다.
* 새 요청이 들어오면 만료된 타임스탬프는 제거한다.
  만료된 스탬프 : 현재 윈도우의 시작 시점보다 오래된 타임스탬프 
* 새 요청의 타임스탬프를 로그에 추가한다.
  * 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다.
  * 그렇지 않을 경우 처리를 거부한다.

#### 장점
* 어느 순간의 윈도우를 보더라도, 허용되는 요청 개수는 시스템의 처리율 한도를 넘지 않는다.

#### 단점
* 메모리 리소스가 많이 필요하다. 거부된 요청의 타임스탬프도 보관해야 하기 때문.



### sliding window counter
고정 윈도우 카운터 + 이동 윈도우 로깅

이동하면서 비율에 따라 현재까지 얼만큼의 요청이 들어왔는지 계산한다.

```
현재 1분간 요청 수 + (직전 1분간의 요청 수 * 이동 윈도우와 직접 1분이 겹치는 비율)
```

#### 장점
* 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
  이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산하기 때문
* 메모리 효율이 좋다.

#### 단점
* 직전 시간대에 도착한 요청이 균등하게 분호되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.(치명적이진 않음)



## 카운터는 어디에 저장할까

캐시.

* 메모리 상에서 동작하기 때문에 빠르다.
* 만료 정책을 지원한다 -> 타임아웃 값이 있어 설정된 시간이 지나면 카운터를 삭제한다.


## 처리율 제한 규칙
보통은 설정 파일 형태로 디스크에 저장한다.


## 처리율 한도 초과 트래픽의 처리

한도 제한에 걸리면 API는 `429(too many requests)` 를 클라이언트에게 보낸다.
경우에 따라서는 한도 제한에 걸린 메세지를 나중에 처리하기 위해 큐에 보관할 수도 있다.
예를 들면, 주문 시스템. 한도에 걸린 주문들을 보관했다가 나중에 처리할 수 있음.


### HTTP 응답 헤더
클라이언트에게 처리율 제한에 관한 정보를 제공하기 위해 HTTP 헤더를 사용할 수 있다.

* `X-Ratelimit-Remaining` : 윈도우 내에 남은 처리 가능 요청의 수
* `X-Ratelimit-Limit` : 매 윈도우마다 클라이언트가 전소할 수 있는 요청의 수
* `X-Ratelimit-Retry-After` : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림


## 분산 환경일 경우
### 경쟁 조건
lock을 사용할 수 있는데, 시스템 성능 하락의 주범이다.

2가지 해결책
* Lua script
* 레디스의 sorted set(ZSET)


### 동기화 이슈
처리율 제한 장치를 나누어 사용하게 되면, 이 장치들끼리 동기화가 되지 않는 문제가 있다.

#### 고정 세션 (X)
같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하면
되긴한데... 

확장 가능하지 않고, 유연하지도 않다.


#### 중앙 집중형 데이터 저장소
redix 같은 걸 쓰자.

## 성능 최적화 

### latency 개선
엣지 서버를 두어, 사용자에게 가까운 데이터 센터를 지원하는 것


### 제한 장치간 데이터 동기화
최종 일관성 모델을 사용해야 한다.


## 그 외
* hard / soft 처리율 제한
  * hard 처리율 제한 : 요청의 개수는 임계치를 절대 넘어설 수 없음
  * soft 처리율 제한 : 요청 개수는 잠시 동안은 임계치를 넘어설 수 있음
* 다양한 계층에서의 처리율 제한
  OSI의 다른 계층에서도 처리율 제한이 가능하다.
* 처리율 제한 회피하기 - 클라이언트를 어떻게 설계하면 좋을 것인가
  * 클라이언트 측 캐시 사용 -> API 호출 횟수 감소
  * 예외나 에러 처리하는 코드 도입 -> 클라이언트에서 예외적인 상황을 복구할 수 있도록
  * 재시도 로직 구현할 때는, 충분한 back-off 시간





